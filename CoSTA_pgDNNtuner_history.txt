


2021-11-14 23:40:49.319552
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}




2021-11-14 23:47:23.965688
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 4, 'n_layers_2': 2, 'max_depth': 80, 'min_depth': 14}
Score to beat: 0.026962206882213024
Changing min_depth from 14 by adding 3
new score 0.027402267910234028
Changing min_depth from 14 by adding -3
new score 0.026509879810606478
Changing min_depth from 11 by adding -2
new score 0.023327187812617535
Changing min_depth from 9 by adding -2
new score 0.028077214654076012
Changing n_layers_1 from 4 by adding 1
new score 0.026925177814513035
Changing n_layers_1 from 4 by adding -1
new score 0.026785771909016286
Changing n_layers_2 from 2 by adding -1
new score 0.028292020414202097
Changing n_layers_2 from 2 by adding 1
new score 0.02852509149074356
Changing max_depth from 80 by adding -20
new score 0.02381479589459395
Changing max_depth from 80 by adding 20
new score 0.02419823603855417
Starting new tuning iteration. Configs now: {'n_layers_1': 4, 'n_layers_2': 2, 'max_depth': 80, 'min_depth': 9}
Score to beat: 0.02806473332424883
Changing max_depth from 80 by adding 20
new score 0.03183848295119445
Changing max_depth from 80 by adding -20
new score 0.028412331397468127
Changing min_depth from 9 by adding 2
new score 0.02998683334945685
Changing min_depth from 9 by adding -2
new score 0.029389972630769035
Changing n_layers_2 from 2 by adding 1
new score 0.02363413939341779
Changing n_layers_2 from 3 by adding 1
new score 0.023126185132839625
Changing n_layers_2 from 4 by adding 1
new score 0.03324074827225898
Changing n_layers_1 from 4 by adding -1
new score 0.029442897339262353
Changing n_layers_1 from 4 by adding 1
new score 0.02362670215693299
Starting new tuning iteration. Configs now: {'n_layers_1': 4, 'n_layers_2': 4, 'max_depth': 80, 'min_depth': 9}
Score to beat: 0.030345123323064764
Changing max_depth from 80 by adding 20
new score 0.029101198804005822
Changing max_depth from 100 by adding 25
new score 0.031233408238094514
Changing min_depth from 9 by adding 2
new score 0.030964959663970636
Changing min_depth from 9 by adding -2
new score 0.028546246378603764
Changing min_depth from 7 by adding -1
new score 0.02044969401654847
Changing min_depth from 6 by adding -1
new score 0.027007610411305682
Changing n_layers_2 from 4 by adding 1
new score 0.023274333299921002
Changing n_layers_2 from 4 by adding -1
new score 0.024988424892932414
Changing n_layers_1 from 4 by adding 1
new score 0.02785097057759834
Changing n_layers_1 from 4 by adding -1
new score 0.019747561376782123
Changing n_layers_1 from 3 by adding -1
new score 0.026668523909120324
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 100, 'min_depth': 6}
Score to beat: 0.026186758957468255
Changing max_depth from 100 by adding 25
new score 0.025348374942294926
Changing max_depth from 125 by adding 31
new score 0.02893542601801456
Changing n_layers_2 from 4 by adding 1
new score 0.02148871751206812
Changing n_layers_2 from 5 by adding 1
new score 0.02383238928595261
Changing min_depth from 6 by adding -1
new score 0.018333797282656696
Changing min_depth from 5 by adding -1
new score 0.024161115725313702
Changing n_layers_1 from 3 by adding 1
new score 0.027581951221240138
Changing n_layers_1 from 3 by adding -1
new score 0.02991683498205864
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 5, 'max_depth': 125, 'min_depth': 5}
Score to beat: 0.02921465548889545
Changing n_layers_2 from 5 by adding -1
new score 0.019176684281314336
Changing n_layers_2 from 4 by adding -1
new score 0.024216745083672258
Changing max_depth from 125 by adding -31
new score 0.02688073960864521
Changing max_depth from 125 by adding 31
new score 0.029063849041359925
Changing min_depth from 5 by adding -1
new score 0.02403278863242518
Changing min_depth from 5 by adding 1
new score 0.028559955541968614
Changing n_layers_1 from 3 by adding 1



2021-11-24 23:49:10.479988
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}




2021-11-24 23:56:28.929127
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}



2021-11-25 00:03:08.544228
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.15384838973877774
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.3747928219780049
Changing l1_penalty from 0.01024 by adding -0.00512
new score 24586961.35470551

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.15643850414774732
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.3380470395270264
Changing l1_penalty from 0.01024 by adding -0.00512
new score 78296881.35638297

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.15380779124219052
Changing l1_penalty from 0.01024 by adding -0.00512
new score 574748055.9444817
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.3697060439353328

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.15443644143539095
Changing l1_penalty from 0.01024 by adding -0.00512
new score 25756346484.467354
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.3745560596920169

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.15330676780216307
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.37329227840656054
Changing l1_penalty from 0.01024 by adding -0.00512
new score 9296282.290119432

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}



2021-11-25 09:08:38.321331
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.1598260478212579
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.3699955095567513
Changing l1_penalty from 0.01024 by adding -0.00512
new score 14638110.64642885

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.01024}
Score to beat: 0.14864669894189836
Changing l1_penalty from 0.01024 by adding -0.00512
new score 27191497.121635195
Changing l1_penalty from 0.01024 by adding 0.01024
new score 0.14697259634180357
Changing l1_penalty from 0.02048 by adding 0.02048



2021-11-25 09:59:39.645806
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.001}
Score to beat: 0.026735810214526604
Changing l1_penalty from 0.001 by adding 0.001
new score 0.0551727537695192
Changing l1_penalty from 0.001 by adding -0.0005
new score 0.00469267264733194
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.03619840501013477
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.0005}
Score to beat: 0.04171143784548051
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.049264456407864574
Changing l1_penalty from 0.0005 by adding 0.0005
new score 0.011381181644195099
Changing l1_penalty from 0.001 by adding 0.001
new score 0.03609767721032358
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.001}
Score to beat: 0.02441844097080375
Changing l1_penalty from 0.001 by adding -0.0005
new score 0.025803983271035096
Changing l1_penalty from 0.001 by adding 0.001
new score 0.035398287016879866

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.001}
Score to beat: 0.006459385830456603
Changing l1_penalty from 0.001 by adding -0.0005
new score 0.04444158877203542
Changing l1_penalty from 0.001 by adding 0.001
new score 0.048858530041034826

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.001}
Score to beat: 0.03204509327192303
Changing l1_penalty from 0.001 by adding 0.001
new score 0.053209030381920354
Changing l1_penalty from 0.001 by adding -0.0005
new score 0.024764882642864385
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.04953720287468862
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.0005}
Score to beat: 0.005816518858967266
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.04332161248594985
Changing l1_penalty from 0.0005 by adding 0.0005
new score 0.02579281414506853

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.0005}
Score to beat: 0.004952194004312202
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.04396978756956886
Changing l1_penalty from 0.0005 by adding 0.0005
new score 0.03737519381020766

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.0005}
Score to beat: 0.048714707537797816
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.03270273633628898
Changing l1_penalty from 0.00025 by adding -0.000125
new score 0.03778591462447552
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.00025}
Score to beat: 0.03637267881046391
Changing l1_penalty from 0.00025 by adding 0.00025
new score 0.011250521300867343
Changing l1_penalty from 0.0005 by adding 0.0005
new score 0.01680034351090381
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.0005}
Score to beat: 0.045944373068889134
Changing l1_penalty from 0.0005 by adding -0.00025
new score 0.022550564220782696
Changing l1_penalty from 0.00025 by adding -0.000125
new score 0.03946770847766188
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 0.00025}
Score to beat: 0.04774405819332871
Changing l1_penalty from 0.00025 by adding -0.000125
new score 0.04180269571449611
Changing l1_penalty from 0.000125 by adding -6.25e-05
new score 0.04033091679529107
Changing l1_penalty from 6.25e-05 by adding -3.125e-05
new score 0.038819562768795376
Changing l1_penalty from 3.125e-05 by adding -1.5625e-05
new score 0.02989733170133828
Changing l1_penalty from 1.5625e-05 by adding -7.8125e-06
new score 0.03663179879550134
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.5625e-05}
Score to beat: 0.03741837816279883
Changing l1_penalty from 1.5625e-05 by adding -7.8125e-06
new score 0.021660099918360317
Changing l1_penalty from 7.8125e-06 by adding -3.90625e-06
new score 0.031444243530435616
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 7.8125e-06}
Score to beat: 0.020365579728877748
Changing l1_penalty from 7.8125e-06 by adding 7.8125e-06
new score 0.030036546070348308
Changing l1_penalty from 7.8125e-06 by adding -3.90625e-06
new score 0.01676896670103924
Changing l1_penalty from 3.90625e-06 by adding -1.953125e-06
new score 0.03055715204726829
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 3.90625e-06}
Score to beat: 0.03753512096647379
Changing l1_penalty from 3.90625e-06 by adding -1.953125e-06
new score 0.03733130393922646
Changing l1_penalty from 1.953125e-06 by adding -9.765625e-07
new score 0.021785531768291674
Changing l1_penalty from 9.765625e-07 by adding -4.8828125e-07
new score 0.022391663887501377
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 9.765625e-07}
Score to beat: 0.009836778617336004
Changing l1_penalty from 9.765625e-07 by adding -4.8828125e-07
new score 0.019233404794675703
Changing l1_penalty from 9.765625e-07 by adding 9.765625e-07
new score 0.030324165164717636

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 9.765625e-07}
Score to beat: 0.01838877148065727
Changing l1_penalty from 9.765625e-07 by adding 9.765625e-07
new score 0.02929521866178896
Changing l1_penalty from 9.765625e-07 by adding -4.8828125e-07
new score 0.02630117892348937

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 9.765625e-07}
Score to beat: 0.02420902745767421
Changing l1_penalty from 9.765625e-07 by adding -4.8828125e-07
new score 0.022004852039937038
Changing l1_penalty from 4.8828125e-07 by adding -2.44140625e-07
new score 0.03823076698680471
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 4.8828125e-07}
Score to beat: 0.01936134206345892
Changing l1_penalty from 4.8828125e-07 by adding -2.44140625e-07
new score 0.04614998338905213
Changing l1_penalty from 4.8828125e-07 by adding 4.8828125e-07
new score 0.03625165941496304

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 4.8828125e-07}
Score to beat: 0.030172198575227148
Changing l1_penalty from 4.8828125e-07 by adding -2.44140625e-07
new score 0.020159095022328023
Changing l1_penalty from 2.44140625e-07 by adding -1.220703125e-07
new score 0.02453240231236692
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 2.44140625e-07}
Score to beat: 0.029664489574155132
Changing l1_penalty from 2.44140625e-07 by adding 2.44140625e-07
new score 0.017257171059854276
Changing l1_penalty from 4.8828125e-07 by adding 4.8828125e-07
new score 0.022089906201062073
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 4.8828125e-07}
Score to beat: 0.028656357692582474
Changing l1_penalty from 4.8828125e-07 by adding 4.8828125e-07
new score 0.031281303025144834
Changing l1_penalty from 4.8828125e-07 by adding -2.44140625e-07
new score 0.013827163371889717
Changing l1_penalty from 2.44140625e-07 by adding -1.220703125e-07
new score 0.01839529297288955
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 2.44140625e-07}
Score to beat: 0.025555007408554375
Changing l1_penalty from 2.44140625e-07 by adding -1.220703125e-07
new score 0.021084023721463632
Changing l1_penalty from 1.220703125e-07 by adding -6.103515625e-08
new score 0.008658416321166467
Changing l1_penalty from 6.103515625e-08 by adding -3.0517578125e-08
new score 0.03013832626651072
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 6.103515625e-08}
Score to beat: 0.033885858145188665
Changing l1_penalty from 6.103515625e-08 by adding -3.0517578125e-08
new score 0.018575690155388423
Changing l1_penalty from 3.0517578125e-08 by adding -1.52587890625e-08
new score 0.017267267637585165
Changing l1_penalty from 1.52587890625e-08 by adding -7.62939453125e-09
new score 0.034070780197364904
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.52587890625e-08}
Score to beat: 0.012287378770824706
Changing l1_penalty from 1.52587890625e-08 by adding 1.52587890625e-08
new score 0.02821373845405578
Changing l1_penalty from 1.52587890625e-08 by adding -7.62939453125e-09
new score 0.021671041274290023

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.52587890625e-08}
Score to beat: 0.015457954993661772
Changing l1_penalty from 1.52587890625e-08 by adding 1.52587890625e-08
new score 0.035203120749630966
Changing l1_penalty from 1.52587890625e-08 by adding -7.62939453125e-09
new score 0.03534093312754703

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.52587890625e-08}
Score to beat: 0.0011052918412686717
Changing l1_penalty from 1.52587890625e-08 by adding 1.52587890625e-08
new score 0.03299185904607719
Changing l1_penalty from 1.52587890625e-08 by adding -7.62939453125e-09
new score 0.03900748732540345

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.52587890625e-08}
Score to beat: 0.045993450769365014
Changing l1_penalty from 1.52587890625e-08 by adding 1.52587890625e-08
new score 0.02709760934156769
Changing l1_penalty from 3.0517578125e-08 by adding 3.0517578125e-08
new score 0.016370678089087723
Changing l1_penalty from 6.103515625e-08 by adding 6.103515625e-08
new score 0.04037836768061411
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 6.103515625e-08}
Score to beat: 0.007165183894625821
Changing l1_penalty from 6.103515625e-08 by adding 6.103515625e-08
new score 0.026709471559685522
Changing l1_penalty from 6.103515625e-08 by adding -3.0517578125e-08
new score 0.03066235251129329

NO CHANGE!
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 6.103515625e-08}
Score to beat: 0.036108807864409745
Changing l1_penalty from 6.103515625e-08 by adding -3.0517578125e-08
new score 0.03131905775566315
Changing l1_penalty from 3.0517578125e-08 by adding -1.52587890625e-08
new score 0.026719101518966847
Changing l1_penalty from 1.52587890625e-08 by adding -7.62939453125e-09
new score 0.02759923094925531
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 4, 'max_depth': 125, 'min_depth': 5, 'l1_penalty': 1.52587890625e-08}



2022-02-26 00:58:08.621610
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 2, 'depth': 80, 'bn_depth': 8, 'lr': 8e-05, 'l1_penalty': 0.01}
Score to beat: 0.06383083549927951
Changing lr from 8e-05 by adding 1
new score nan
Changing l1_penalty from 0.01 by adding 0.01



2022-02-26 01:23:27.513368
Using training parameters: time_steps=500, {'lr': 8e-05, 'patience': [20, 20], 'epochs': [2000, 2000], 'min_epochs': [50, 50]}

Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 2, 'depth': 80, 'bn_depth': 8, 'l1_penalty': 0.01}
Score to beat: 0.24371170473942738
Changing n_layers_2 from 2 by adding -1
new score 0.13907401676428477
Changing depth from 80 by adding 20
new score 0.045036985458892134
Changing depth from 100 by adding 25
new score 0.07456587583178242
Changing n_layers_1 from 1 by adding 1
new score 0.13501955088737097
Changing l1_penalty from 0.01 by adding 0.01
new score 0.2678732529243561
Changing l1_penalty from 0.01 by adding -0.005
new score 0.05633303393232688
Changing bn_depth from 8 by adding 2
new score 0.10471935208629417
Changing bn_depth from 8 by adding -2
new score 0.14794655582433858
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 1, 'depth': 100, 'bn_depth': 8, 'l1_penalty': 0.01}
Score to beat: 0.10121696052287732
Changing n_layers_2 from 1 by adding 1
new score 0.5548126247807201
Changing n_layers_1 from 1 by adding 1
new score 0.059234854628516506
Changing n_layers_1 from 2 by adding 1
new score 0.4036928925315006
Changing depth from 100 by adding 25
new score 0.052469860152847145
Changing depth from 125 by adding 31
new score 0.056864081936280494
Changing bn_depth from 8 by adding 2
new score 0.049360240068314264
Changing bn_depth from 10 by adding 2
new score 0.05273697795956729
Changing l1_penalty from 0.01 by adding 0.01
new score 0.43976561825657895
Changing l1_penalty from 0.01 by adding -0.005
new score 0.09187941709001107
Starting new tuning iteration. Configs now: {'n_layers_1': 2, 'n_layers_2': 1, 'depth': 125, 'bn_depth': 10, 'l1_penalty': 0.01}
Score to beat: 0.24878751373061495
Changing l1_penalty from 0.01 by adding -0.005
new score 0.06885737070335748
Changing l1_penalty from 0.005 by adding -0.0025
new score 0.11734362476732005
Changing n_layers_1 from 2 by adding 1
new score 0.0811680268323263
Changing n_layers_1 from 2 by adding -1
new score 0.06574104255103402
Changing n_layers_2 from 1 by adding 1
new score 0.117230227569152
Changing depth from 125 by adding -31
new score 0.06375759360476646
Changing depth from 94 by adding -23
new score 0.0698374236527032
Changing bn_depth from 10 by adding 2
new score 0.0625266202009267
Changing bn_depth from 12 by adding 3
new score 0.06254901641908421
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 1, 'depth': 94, 'bn_depth': 12, 'l1_penalty': 0.005}
Score to beat: 0.05114741324007453
Changing n_layers_1 from 1 by adding 1
new score 0.06601538767578304
Changing depth from 94 by adding -23
new score 0.07656827525350772
Changing depth from 94 by adding 23
new score 0.05653379153307049
Changing bn_depth from 12 by adding 3
new score 0.0907261253277041
Changing bn_depth from 12 by adding -3
new score 0.050694439931875085
Changing bn_depth from 9 by adding -2
new score 0.05932504069968565
Changing l1_penalty from 0.005 by adding 0.005
new score 0.10091665330045703
Changing l1_penalty from 0.005 by adding -0.0025
new score 0.05881684064492591
Changing n_layers_2 from 1 by adding 1
new score 0.09365949341914087
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 1, 'depth': 94, 'bn_depth': 9, 'l1_penalty': 0.005}
Score to beat: 0.07062596294756279
Changing n_layers_1 from 1 by adding 1
new score 0.06594278695163244
Changing n_layers_1 from 2 by adding 1
new score 0.05692007504868343
Changing n_layers_1 from 3 by adding 1
new score 0.07779890695616862
Changing depth from 94 by adding -23
new score 0.07470693771137227
Changing depth from 94 by adding 23
new score 0.07944509196568114
Changing l1_penalty from 0.005 by adding 0.005
new score 0.056195873721249845
Changing l1_penalty from 0.01 by adding 0.01
new score 0.423337685171696
Changing bn_depth from 9 by adding 2
new score 0.34828296801861347
Changing bn_depth from 9 by adding -2
new score 0.34141787641981913
Changing n_layers_2 from 1 by adding 1
new score 0.4658936583289561
Starting new tuning iteration. Configs now: {'n_layers_1': 3, 'n_layers_2': 1, 'depth': 94, 'bn_depth': 9, 'l1_penalty': 0.01}
Score to beat: 0.1708778166580906
Changing n_layers_1 from 3 by adding -1
new score 0.08323994280839284
Changing n_layers_1 from 2 by adding -1
new score 0.08538735868701908
Changing l1_penalty from 0.01 by adding 0.01
new score 0.32646296604144337
Changing l1_penalty from 0.01 by adding -0.005
new score 0.08076621543208742
Changing l1_penalty from 0.005 by adding -0.0025
new score 0.04985350299555802
Changing l1_penalty from 0.0025 by adding -0.00125
new score 0.043261065084621804
Changing l1_penalty from 0.00125 by adding -0.000625
new score 0.08224173983153847
Changing depth from 94 by adding 23
new score 0.026367405415839852
Changing depth from 117 by adding 29
new score 0.030171112318179386
Changing n_layers_2 from 1 by adding 1
new score 0.03878920711265093
Changing bn_depth from 9 by adding 2
new score 0.056772908357193654
Changing bn_depth from 9 by adding -2
new score 0.05190748118663551
Starting new tuning iteration. Configs now: {'n_layers_1': 2, 'n_layers_2': 1, 'depth': 117, 'bn_depth': 9, 'l1_penalty': 0.00125}
Score to beat: 0.05805858940656902
Changing n_layers_1 from 2 by adding 1
new score 0.06636776835964472
Changing n_layers_1 from 2 by adding -1
new score 0.05710285791449658
Changing n_layers_2 from 1 by adding 1
new score 0.016480847048784105
Changing n_layers_2 from 2 by adding 1
new score 0.011112247315359477
Changing n_layers_2 from 3 by adding 1
new score 0.03548987815513176
Changing l1_penalty from 0.00125 by adding 0.00125
new score 0.051199831974751295
Changing l1_penalty from 0.00125 by adding -0.000625
new score 0.09811609772459295
Changing depth from 117 by adding -29
new score 0.05984238566980766
Changing depth from 117 by adding 29
new score 0.023396219977117574
Changing bn_depth from 9 by adding 2
new score 0.023730882506967303
Changing bn_depth from 9 by adding -2
new score 0.03375625493869173
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 3, 'depth': 117, 'bn_depth': 9, 'l1_penalty': 0.00125}
Score to beat: 0.02035327652771466
Changing l1_penalty from 0.00125 by adding 0.00125
new score 0.04099200339802361
Changing l1_penalty from 0.00125 by adding -0.000625
new score 0.04048873007315325
Changing n_layers_2 from 3 by adding -1
new score 0.04463443705159314
Changing n_layers_2 from 3 by adding 1
new score 0.01749716329682987
Changing n_layers_2 from 4 by adding 1
new score 0.06186835646651263
Changing n_layers_1 from 1 by adding 1
new score 0.021268885415459998
Changing bn_depth from 9 by adding 2
new score 0.053145579332937384
Changing bn_depth from 9 by adding -2
new score 0.010825704605023138
Changing bn_depth from 7 by adding -1
new score 0.05012932836007737
Changing depth from 117 by adding 29
new score 0.04038333291754016
Changing depth from 117 by adding -29
new score 0.010752180037430132
Changing depth from 88 by adding -22
new score 0.020549313730273768
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 4, 'depth': 88, 'bn_depth': 7, 'l1_penalty': 0.00125}
Score to beat: 0.02596698229803841
Changing l1_penalty from 0.00125 by adding 0.00125
new score 0.02694332797068907
Changing l1_penalty from 0.00125 by adding -0.000625
new score 0.020788887222920535
Changing l1_penalty from 0.000625 by adding -0.0003125
new score 0.02351873609015777
Changing bn_depth from 7 by adding -1
new score 0.032680555095402096
Changing bn_depth from 7 by adding 1
new score 0.04800386187647987
Changing depth from 88 by adding 22
new score 0.039893719146505746
Changing depth from 88 by adding -22
new score 0.02076240007421369
Changing depth from 66 by adding -16
new score 0.028700141411196964
Changing n_layers_2 from 4 by adding 1
new score 0.03448164963779658
Changing n_layers_2 from 4 by adding -1
new score 0.06644051662599396
Changing n_layers_1 from 1 by adding 1
new score 0.05550511660411757
Starting new tuning iteration. Configs now: {'n_layers_1': 1, 'n_layers_2': 4, 'depth': 66, 'bn_depth': 7, 'l1_penalty': 0.000625}
Score to beat: 0.01826808382942581
Changing n_layers_1 from 1 by adding 1
new score 0.064749003772841
Changing bn_depth from 7 by adding -1
